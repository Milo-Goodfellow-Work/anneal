#!/usr/bin/env python3
"""
Anneal Helpers - Configuration, utilities, tools, and validation.
"""
from __future__ import annotations

import os
import re
import time
import tomllib
import subprocess
from pathlib import Path
from typing import List, Optional, Dict, Tuple, Any, NamedTuple


# ============================================================
# Configuration
# ============================================================

SECRETS_FILE = Path("secrets.toml")

SPEC_DIR = Path("spec").resolve()
SPEC_SRC_DIR = SPEC_DIR / "Spec"
EXAMPLES_DIR = Path("examples").resolve()

MODEL_ID = "gpt-5.2"

PRINT_TRUNC = 4000
MAX_TOOL_READ_CHARS = 80_000

# "Must converge" philosophy:
# - we keep trying for a long time and we do NOT proceed to later stages if we fail.
MAX_REPAIR_TURNS_PER_FILE = 80
MAX_REPAIR_TURNS_GLOBAL = 120
MAX_SESSION_TURNS = 16

# Autogenerated, model-writable artifacts outside Spec/Spec
SPEC_TESTS_DIR = SPEC_DIR / "tests"
SPEC_REPORTS_DIR = SPEC_DIR / "reports"

# Files that aggregate imports / define the environment surface.
# We auto-generate and keep them read-only for the model.
LOCKED_LEAN_FILENAMES = {"Prelude.lean"}  # plus per-project root module "<project>.lean" added dynamically

# Prelude policy: we own these imports; generated files should only import Spec.Prelude.
PRELUDE_REQUIRED_IMPORTS = [
    "Std",
    "Std.Data.TreeMap",
    "Std.Data.TreeSet",
    "Std.Data.HashMap",
    "Std.Data.HashSet",
]

# Differential testing robustness requirements
DIFF_REQUIRED_RUNS = 5          # number of distinct seeds / runs required to pass before equivalence can complete
DIFF_MIN_CASES_PER_RUN = 5      # minimum number of command lines / cases per run
DIFF_SEED_START = 1             # seeds will be DIFF_SEED_START..DIFF_SEED_START+DIFF_REQUIRED_RUNS-1

# Subprocess timeouts
GEN_TIMEOUT_S = 8
C_RUN_TIMEOUT_S = 8
LEAN_RUN_TIMEOUT_S = 3000  # increase to avoid "fake completion" on 10s timeouts

FORBIDDEN_TRANSLATION_PHRASES = [
    "for this benchmark",
    "as a benchmark",
    "placeholder",
    "stub",
    "not implemented",
    "todo:",
    "TODO",
    "a full translation would",
    "we return `true` as a placeholder",
    "return `true` as a placeholder",
    "return true as a placeholder",
    "not going to fully complete",
    "not going to actually fully complete",
    "for the purpose of this benchmark",
    "for the purposes of this benchmark",
    "simplified for benchmark",
]

# If a function name suggests safety checking, ban constant-true bodies.
SUSPICIOUS_SAFETY_FN_TOKENS = [
    "verify",
    "integrity",
    "check",
    "invariant",
    "validate",
    "wellformed",
    "well_formed",
]


# ============================================================
# Utilities
# ============================================================

def log(msg: str) -> None:
    print(f"[Anneal] {msg}", flush=True)

def trunc(s: str, n: int = PRINT_TRUNC) -> str:
    if s is None:
        return ""
    return s if len(s) <= n else (s[:n] + f"\n... (truncated, total {len(s)} chars)")

def trunc_tail(s: str, n: int = PRINT_TRUNC) -> str:
    """Truncate from the BEGINNING, keeping the END of the string.
    
    Useful for build output where warnings come first and actual errors come last.
    Lean's lake build puts errors at the end, so we need to preserve those.
    """
    if s is None:
        return ""
    if len(s) <= n:
        return s
    return f"(... truncated {len(s) - n} chars from start ...)\n" + s[-(n):]

def load_secrets() -> dict:
    if not SECRETS_FILE.exists():
        key = os.environ.get("OPENAI_API_KEY")
        if key:
            aristotle_key = os.environ.get("ARISTOTLE_API_KEY")
            secrets = {"OPENAI_API_KEY": key}
            if aristotle_key:
                secrets["ARISTOTLE_API_KEY"] = aristotle_key
            return {"secrets": secrets}
        raise FileNotFoundError(f"{SECRETS_FILE} not found and OPENAI_API_KEY not in env.")
    with SECRETS_FILE.open("rb") as f:
        return tomllib.load(f)

def _safe_relpath(p: str) -> str:
    p = (p or "").replace("\\", "/").lstrip("/")
    if p == "" or p == ".":
        raise ValueError("Empty path")
    parts = [x for x in p.split("/") if x not in ("", ".")]
    if any(x == ".." for x in parts):
        raise ValueError(f"Path traversal not allowed: {p}")
    return "/".join(parts)

def _read_text_file(p: Path) -> str:
    return p.read_text(encoding="utf-8", errors="replace")

def _write_text_file(p: Path, content: str) -> None:
    p.parent.mkdir(parents=True, exist_ok=True)
    p.write_text(content, encoding="utf-8")

def list_project_files(base_dir: Path) -> List[str]:
    files: List[str] = []
    if not base_dir.exists():
        return files
    for root, dirs, filenames in os.walk(base_dir):
        if ".git" in dirs:
            dirs.remove(".git")
        if "__pycache__" in dirs:
            dirs.remove("__pycache__")
        for fn in filenames:
            abs_p = Path(root) / fn
            rel_p = abs_p.relative_to(base_dir)
            files.append(str(rel_p).replace("\\", "/"))
    return sorted(files)

def list_lean_files(base_dir: Path) -> List[str]:
    files: List[str] = []
    if not base_dir.exists():
        return files
    for root, dirs, filenames in os.walk(base_dir):
        if ".git" in dirs:
            dirs.remove(".git")
        if "__pycache__" in dirs:
            dirs.remove("__pycache__")
        for fn in filenames:
            if fn.endswith(".lean"):
                abs_p = Path(root) / fn
                rel_p = abs_p.relative_to(base_dir)
                files.append(str(rel_p).replace("\\", "/"))
    return sorted(files)

def run_lake_build(cwd: Path) -> str:
    start = time.time()
    try:
        res = subprocess.run(
            ["lake", "build"],
            cwd=str(cwd),
            capture_output=True,
            text=True,
            check=False,
        )
        elapsed = time.time() - start
        if res.returncode == 0:
            return f"Build Success ({elapsed:.2f}s)"
        return f"Build Failed (exit={res.returncode}, {elapsed:.2f}s):\n{res.stderr}\n{res.stdout}"
    except Exception as e:
        return f"Error running lake build: {e}"

def run_lake_build_target(cwd: Path, target: Optional[str] = None) -> str:
    start = time.time()
    cmd = ["lake", "build"]
    if target:
        cmd.append(target)
    try:
        res = subprocess.run(cmd, cwd=str(cwd), capture_output=True, text=True, check=False)
        elapsed = time.time() - start
        if res.returncode == 0:
            return f"Build Success ({elapsed:.2f}s)"
        return f"Build Failed (exit={res.returncode}, {elapsed:.2f}s):\n{res.stderr}\n{res.stdout}"
    except Exception as e:
        return f"Error running lake build: {e}"

def module_name_from_lean_path(rel_path_under_spec: str) -> Optional[str]:
    p = Path(rel_path_under_spec)
    if p.suffix != ".lean":
        return None
    return "Spec." + ".".join(p.with_suffix("").parts)

def _slug_to_camel(s: str) -> str:
    parts = re.split(r"[^A-Za-z0-9]+", s)
    parts = [x for x in parts if x]
    if not parts:
        return "X"
    out = "".join(x[:1].upper() + x[1:] for x in parts)
    if out and out[0].isdigit():
        out = "X" + out
    return out

def _lean_out_path_for_source(project: str, src_rel: str, used: Dict[str, int]) -> str:
    src = Path(src_rel)
    stem = src.stem
    parent = str(src.parent).replace("\\", "/")
    if parent in (".", ""):
        base = _slug_to_camel(stem)
    else:
        base = _slug_to_camel(parent.replace("/", "_") + "_" + stem)
    name = base
    if name in used:
        used[name] += 1
        name = f"{name}{used[name]}"
    else:
        used[name] = 1
    return f"{project}/{name}.lean"

def _is_source_file(rel: str) -> bool:
    ext = Path(rel).suffix.lower()
    return ext in {".c", ".h", ".cc", ".cpp", ".hpp"}

def _limit_lines(lines: List[str], max_lines: int = 220) -> List[str]:
    if len(lines) <= max_lines:
        return lines
    return lines[:max_lines] + [f"... ({len(lines)-max_lines} more lines omitted) ..."]


# ============================================================
# Lean error parsing (for targeted repair)
# ============================================================

LEAN_ERR_RE = re.compile(
    r"^error:\s+(?P<file>[^:]+):(?P<line>\d+):(?P<col>\d+):\s+(?P<msg>.*)$",
    re.MULTILINE,
)

class LeanError(NamedTuple):
    file: str
    line: int
    col: int
    msg: str

def parse_lean_errors(build_output: str, *, max_n: int = 6) -> List[LeanError]:
    errs: List[LeanError] = []
    for m in LEAN_ERR_RE.finditer(build_output):
        errs.append(
            LeanError(
                file=m.group("file").strip(),
                line=int(m.group("line")),
                col=int(m.group("col")),
                msg=m.group("msg").strip(),
            )
        )
        if len(errs) >= max_n:
            break
    return errs

def excerpt_around(text: str, line_1based: int, *, radius: int = 14) -> str:
    lines = text.splitlines()
    i = max(1, line_1based) - 1
    lo = max(0, i - radius)
    hi = min(len(lines), i + radius + 1)
    out: List[str] = []
    for idx in range(lo, hi):
        prefix = ">>" if idx == i else "  "
        out.append(f"{prefix} {idx+1:4d}: {lines[idx]}")
    return "\n".join(out)


# ============================================================
# Prelude + locked files
# ============================================================

PRELUDE_PATH = SPEC_SRC_DIR / "Prelude.lean"

def ensure_prelude_and_lockdown() -> None:
    """
    Ensure Prelude exists and contains a conservative, useful import surface.
    The model is prevented from writing it; the script owns it.
    """
    SPEC_SRC_DIR.mkdir(parents=True, exist_ok=True)

    required_import_lines = [f"import {m}" for m in PRELUDE_REQUIRED_IMPORTS]

    if not PRELUDE_PATH.exists():
        content = (
            "\n".join(required_import_lines)
            + "\n\nnamespace Spec\n\n"
              "-- Shared abbreviations and safe utilities live here.\n"
              "-- Generated modules must import ONLY Spec.Prelude (plus Spec.<project>.* if needed).\n\n"
              "abbrev U8  := UInt8\n"
              "abbrev U16 := UInt16\n"
              "abbrev U32 := UInt32\n"
              "abbrev U64 := UInt64\n\n"
              "end Spec\n"
        )
        _write_text_file(PRELUDE_PATH, content)
        log(f"Wrote {PRELUDE_PATH}")
        return

    existing = _read_text_file(PRELUDE_PATH)
    existing_imports = set(re.findall(r"^\s*import\s+([A-Za-z0-9_.]+)\s*$", existing, flags=re.MULTILINE))
    missing = [m for m in PRELUDE_REQUIRED_IMPORTS if m not in existing_imports]
    if missing:
        prepend = "\n".join([f"import {m}" for m in missing]) + "\n"
        _write_text_file(PRELUDE_PATH, prepend + existing)
        log(f"Updated {PRELUDE_PATH}: prepended missing imports: {missing}")


# ============================================================
# Tool schema
# ============================================================

def _tool(name: str, description: str, properties: Dict[str, Any], required: List[str]) -> Dict[str, Any]:
    return {
        "type": "function",
        "name": name,
        "description": description,
        "strict": True,
        "parameters": {
            "type": "object",
            "properties": properties,
            "required": required,
            "additionalProperties": False,
        },
    }

TOOLS_SCHEMA = [
    _tool(
        "read_source_file",
        "Read content of a source file from source project (examples/<project>/).",
        {"path": {"type": "string", "description": "Relative path under examples/<project>/"}},
        ["path"],
    ),
    _tool(
        "read_lean_file",
        "Read content of a Lean file from spec/Spec/ (relative path).",
        {"path": {"type": "string", "description": "Relative path under spec/Spec/ (e.g., 'order_engine/Engine.lean')"}},
        ["path"],
    ),
    _tool(
        "write_lean_file",
        "Write or overwrite a Lean file under spec/Spec/ (relative path). Writes are restricted to pre-autogenerated files only.",
        {
            "path": {"type": "string", "description": "Relative path under spec/Spec/"},
            "content": {"type": "string", "description": "Full content of the Lean file"},
        },
        ["path", "content"],
    ),
    _tool(
        "write_text_file",
        "Write or overwrite a non-Lean file. Writes are restricted to pre-autogenerated files only.",
        {
            "path": {"type": "string", "description": "Relative path under the repository root (e.g., 'spec/tests/harness.c')"},
            "content": {"type": "string", "description": "Full content of the file"},
        },
        ["path", "content"],
    ),
    _tool(
        "verify_build",
        "Run lake build in the spec/ directory.",
        {},
        [],
    ),
    _tool(
        "restart_translation",
        "CRITICAL: Call this only if you determine that the current translation is fundamentally flawed and cannot be fixed by editing files. This will discard current progress and restart the Translation stage with your feedback.",
        {
            "reason": {"type": "string", "description": "Detailed explanation of why the semantic mismatch is unfixable and requires re-translation."}
        },
        ["reason"],
    ),
    _tool(
        "run_differential_test",
        "Run robust differential tests (multiple seeds) between C harness and Lean harness; returns JSON status.",
        {
            "gen_script_path": {"type": "string", "description": "Path to python input generator (relative to repo root)"},
            "c_harness_path": {"type": "string", "description": "Path to C harness source (relative to repo root)"},
            "lean_harness_path": {"type": "string", "description": "Path to Lean harness source (relative to spec/Spec/)"},
        },
        ["gen_script_path", "c_harness_path", "lean_harness_path"],
    ),
    _tool(
        "submit_stage",
        "Signal that the current stage is complete (this may be denied if success criteria are not met).",
        {"summary": {"type": "string", "description": "Brief summary"}},
        ["summary"],
    ),
]


# ============================================================
# Import policy + content validators
# ============================================================

IMPORT_RE = re.compile(r"^\s*import\s+([A-Za-z0-9_.]+)\s*$", re.MULTILINE)

# Verif.lean anti-smuggling policy:
# - Verif.lean may contain theorems/lemmas (and supporting proof code), but must not define executable entities.
# - This prevents runtime behavior from being "smuggled" through Verif.lean (which is imported for Aristotle).
VERIF_FORBIDDEN_TOPLEVEL_RE = re.compile(
    r"^\s*(?:@\[[^\]]*\]\s*)*(?:(?:private|protected|noncomputable|unsafe|partial)\s+)*"
    r"(def|abbrev|instance|structure|inductive|axiom|constant|macro|syntax|notation|attribute)\b",
    re.MULTILINE,
)

def validate_imports_for_project(project: str, content: str) -> Tuple[bool, List[str]]:
    """
    Policy:
    - Must import Spec.Prelude at least once.
    - May additionally import Spec.<project>.* (rarely needed).
    - No Std / Mathlib / anything else in generated files.
    """
    mods = IMPORT_RE.findall(content)
    bad: List[str] = []
    for mod in mods:
        if mod == "Spec.Prelude":
            continue
        if mod.startswith(f"Spec.{project}."):
            continue
        if mod == f"Spec.{project}":
            continue
        bad.append(mod)

    if "Spec.Prelude" not in mods:
        bad.append("(missing Spec.Prelude)")

    return (len(bad) == 0, bad)

IMPORT_FAILED_RE = re.compile(r"import\s+(?P<mod>[A-Za-z0-9_.]+)\s+failed")
ENV_CONTAINS_FROM_RE = re.compile(
    r"environment already contains '[^']+'\s+from\s+(?P<mod>[A-Za-z0-9_.]+)"
)

def module_to_spec_relpath(mod: str) -> Optional[str]:
    # Spec.order_engine.Engine2 -> order_engine/Engine2.lean
    if not mod.startswith("Spec."):
        return None
    parts = mod.split(".")[1:]  # drop leading "Spec"
    if not parts:
        return None
    return "/".join(parts) + ".lean"

def extract_failed_import_module(msg: str) -> Optional[str]:
    m = IMPORT_FAILED_RE.search(msg or "")
    return m.group("mod") if m else None

def _contains_forbidden_phrases(s: str) -> Optional[str]:
    lo = s.lower()
    for ph in FORBIDDEN_TRANSLATION_PHRASES:
        if ph.lower() in lo:
            return ph
    return None

def _looks_like_constant_true_safety_check(lean: str) -> bool:
    """
    Heuristic: if there is a def whose name suggests "verify/check/integrity" and its body is literally `true`,
    reject it (outside Verif.lean).
    """
    for m in re.finditer(r"^\s*(?:partial\s+)?def\s+([A-Za-z0-9_']+)[^:=\n]*:=\s*true\s*$", lean, flags=re.MULTILINE):
        name = m.group(1).lower()
        if any(tok in name for tok in SUSPICIOUS_SAFETY_FN_TOKENS):
            return True
    return False

def validate_basic_lean_shape(project: str, rel_path: str, content: str) -> Tuple[bool, str]:
    stripped = content.strip()
    if not stripped:
        return False, "File content is empty or whitespace."

    if "namespace" not in content or f"namespace Spec.{project}" not in content:
        return False, f"Missing required namespace 'namespace Spec.{project}'."

    if f"end Spec.{project}" not in content:
        return False, f"Missing required end marker 'end Spec.{project}'."

    ok_imports, bad = validate_imports_for_project(project, content)
    if not ok_imports:
        return False, f"Import policy violated: {bad}. Only 'import Spec.Prelude' (and optionally Spec.{project}.*) allowed."

    is_verif = rel_path.replace("\\", "/").endswith("/Verif.lean")
    if is_verif:
        # Proofs-only: no executable definitions or axioms/macros/etc.
        if VERIF_FORBIDDEN_TOPLEVEL_RE.search(content):
            return (
                False,
                "Verif.lean is proofs-only (anti-smuggling): it must not contain def/abbrev/instance/structure/"
                "inductive/axiom/constant/macro/syntax/notation/attribute.",
            )
        # 'sorry' is allowed here by design.
        return True, ""

    # Non-Verif files: strict anti-laziness and anti-placeholder rules.
    if re.search(r"\bsorry\b", content):
        return False, "Forbidden: 'sorry' is not allowed in translated/runtime Lean modules (only allowed in Verif.lean)."

    bad_phrase = _contains_forbidden_phrases(content)
    if bad_phrase:
        return False, f"Forbidden phrase detected in translated code: '{bad_phrase}'. Safety-critical mode forbids placeholders/benchmark language."

    if _looks_like_constant_true_safety_check(content):
        return False, "Forbidden: safety-checking function appears to be a constant `true`. Implement the real check."

    return True, ""
